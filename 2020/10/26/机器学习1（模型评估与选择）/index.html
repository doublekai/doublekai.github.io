<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 机器学习1（模型评估与选择 · Doublekai的博客</title><meta name="description" content="机器学习1（模型评估与选择 - DOUBLEKAI"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://www.doublekai.com/atom.xml" title="Doublekai的博客"><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Doublekai的博客" type="application/atom+xml">
</head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/doublekai?tab=repositories" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about/" target="_self" class="nav-list-link">ABOUT</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">机器学习1（模型评估与选择</h1><div class="post-info">Oct 26, 2020</div><div class="post-content"><p>我们把分类错误的样本数占样本总数的比例称为“错误率”(error rate)，即如果在m个样本中有a个样本分类错误，则错误率E=a/m；相应的，1-a/m称为“精度”，即“精度=1-错误率”。更一般地，我们把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”(error)，学习器在训练集上的误差称为“训练误差”(training error)或“经验误差”(empirical error)，在新样本上的误差称为“泛化误差”(generalization error)。显然，我们希望得到泛化误差小的学习器。然而，我们事先并不知道新样本是什么样，实际能做的是努力使经验误差最小化。在很多情况下，我们可以学得一个经验误差很小，在训练集上表现很好的学习器，例如甚至对所有训练样本都分类正确，即分类错误率为零，分类精度为100%，但这是不是我们想要的学习器呢？遗憾的是，这样的学习器在多数情况下都不好。</p>
<p>完整的数据集表示为T={(x1,y1),(x2,y2),(x2,y2),…,(xi,yi)}，对于一个学习机而言，不是所有的数据都用于训练学习模型，而是会被分为三个部分：训练数据、交叉验证数据、测试数据。</p>
<ul>
<li>  训练数据(training data)：顾名思义，训练数据用于训练学习模型，通常比例不低于总数据量的一半。</li>
<li>  交叉验证数据(cross validation data)：交叉验证数据用于衡量训练过程中模型的好坏，因为机器学习算法大部分都不是通过解析法得到的，而是通过不断迭代来慢慢优化模型，所以交叉验证数据就可以用来监视模型训练时候的性能变化。</li>
<li>  测试数据(testing data)：在模型训练好了之后，测试数据用于衡量最终模型的性能好坏，这也是模型性能好坏的衡量指标，交叉验证的指标只能用于监视和辅助模型训练，不能用来代表模型好坏，所以哪怕交叉验证的准确度是100%而测试数据的准确度是10%，那么模型也是不能被认可的。通常交叉验证和测试数据的比例各占一小半。</li>
</ul>
<p>欠拟合时，模型在训练集和测试集上都有很大误差（高偏差）；过拟合时，模型在训练集上可能误差很小，但是在测试集上误差很大（高方差）。如果模型在训练集上误差很大，且在测试集上的误差要更大的多，那么该模型同时有着高偏差和高方差。</p>
<p>  防止欠拟合方法：不要选用过于简单的模型</p>
<p>  防止过拟合方法：不要选用过于复杂的模型；数据集扩增（可以是寻找更多的训练集，也可以是对原训练集做处理，比如对原图片翻转缩放裁剪等）；正则化；Early stopping(在测试集上的误差率降到最低就停止训练，而不是不断降低在训练集上的误差)</p>
</div></article></div></main><footer><div class="paginator"><a href="/2020/10/26/Django%E5%85%A5%E9%97%A8/" class="prev">PREV</a><a href="/2019/04/16/Vue.js%E5%9F%BA%E7%A1%80%E6%8C%87%E4%BB%A4%E5%92%8C%E4%BD%BF%E7%94%A8/" class="next">NEXT</a></div><div class="copyright"><p>© 2015 - 2026 DOUBLEKAI</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>